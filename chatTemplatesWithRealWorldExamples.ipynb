{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgPRvBcEMerd"
   },
   "source": [
    "# Common Template Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKFMQ6thKko3"
   },
   "source": [
    "Key differences between these formats include:\n",
    "\n",
    "\n",
    "\n",
    "1.   System Message Handling:\n",
    "\n",
    "    *   Llama 2 wraps system messages in <<SYS>> tags\n",
    "    *   Llama 3 uses <|system|> tags with </s> endings\n",
    "    *   Mistral includes system message in the first instruction\n",
    "    *   Qwen uses explicit system role with <|im_start|> tags\n",
    "    *   ChatGPT uses SYSTEM: prefix\n",
    "    *   List item\n",
    "\n",
    "\n",
    "2.   Message Boundaries:\n",
    "\n",
    "    *  Llama 2 uses [INST] and [/INST] tags\n",
    "    *  Llama 3 uses role-specific tags (<|system|>, <|user|>, <|assistant|>) with </    s> endings\n",
    "    *  Mistral uses [INST] and [/INST] with <s> and </s>\n",
    "    *  Qwen uses role-specific start/end tokens\n",
    "\n",
    "3.   Special Tokens:\n",
    "\n",
    "    *  Llama 2 uses <s> and </s> for conversation boundaries\n",
    "    *  Llama 3 uses </s> to end each message\n",
    "    *  Mistral uses <s> and </s> for turn boundaries\n",
    "    *  Qwen uses role-specific start/end tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QT_BJvkoMGms"
   },
   "source": [
    "Understanding these differences is key to working with various models. Let’s look at how the transformers library helps us handle these variations automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GVHSZMweMNOl",
    "outputId": "dcf13226-845b-4a50-a062-8f9e858d435c"
   },
   "outputs": [],
   "source": [
    "# Install the requirements in Google Colab\n",
    "!pip -q install transformers datasets trl huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qz-_Q5AyMFTE"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# These will use different templates automatically\n",
    "mistral_tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "qwen_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-7B-Chat\", trust_remote_code=True)\n",
    "smol_tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-135M-Instruct\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "]\n",
    "\n",
    "# Each will format according to its model's template\n",
    "mistral_chat = mistral_tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "# qwen_chat = qwen_tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "smol_chat = smol_tokenizer.apply_chat_template(messages, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8MJdrliM48-",
    "outputId": "c4a169ba-0e2b-4ff2-9d83-915c6bc73291"
   },
   "outputs": [],
   "source": [
    "print(\"Mistral Chat Template:\", mistral_chat)\n",
    "print(\"\\n\")\n",
    "# print(\"Qwen Chat Template:\", qwen_chat)\n",
    "print(\"Smol Chat Template:\", smol_chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iApGMSPFO7vK"
   },
   "source": [
    "# Advanced Features\n",
    "Chat templates can handle more complex scenarios beyond just conversational interactions, including:\n",
    "\n",
    "1. Tool Use: When models need to interact with external tools or APIs\n",
    "2. Multimodal Inputs: For handling images, audio, or other media types\n",
    "3. Function Calling: For structured function execution\n",
    "4. Multi-turn Context: For maintaining conversation history  \n",
    "When implementing advanced features: - Test thoroughly with your specific model. Vision and tool use template are particularly diverse. - Monitor token usage carefully between each feature and model. - Document the expected format for each feature  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L27IpNdDPS89"
   },
   "source": [
    "For multimodal conversations, chat templates can include image references or base64-encoded images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcXMRfYSPP-0"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful vision assistant that can analyze images.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"What's in this image?\"},\n",
    "            {\"type\": \"image\", \"image_url\": \"https://example.com/image.jpg\"},\n",
    "        ],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtH_oljIPVfc"
   },
   "source": [
    "Here’s an example of a chat template with tool use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2FZzqKUPXad"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an AI assistant that can use tools. Available tools: calculator, weather_api\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"What's 123 * 456 and is it raining in Paris?\"},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Let me help you with that.\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"tool\": \"calculator\",\n",
    "                \"parameters\": {\"operation\": \"multiply\", \"x\": 123, \"y\": 456},\n",
    "            },\n",
    "            {\"tool\": \"weather_api\", \"parameters\": {\"city\": \"Paris\", \"country\": \"France\"}},\n",
    "        ],\n",
    "    },\n",
    "    {\"role\": \"tool\", \"tool_name\": \"calculator\", \"content\": \"56088\"},\n",
    "    {\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_name\": \"weather_api\",\n",
    "        \"content\": \"{'condition': 'rain', 'temperature': 15}\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73uXq6uCP1nd"
   },
   "source": [
    "# Best Practices\n",
    "### General Guidelines\n",
    "When working with chat templates, follow these key practices:\n",
    "\n",
    "1. **Consistent Formatting**: Always use the same template format throughout your application\n",
    "2. **Clear Role Definition**: Clearly specify roles (system, user, assistant, tool) for each message\n",
    "3. **Context Managemen**t: Be mindful of token limits when maintaining conversation history\n",
    "4. **Error Handling**: Include proper error handling for tool calls and multimodal inputs\n",
    "5. **Validation**: Validate message structure before sending to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZAvFVIAtFlq"
   },
   "source": [
    "# Exploring Chat Templates with SmolLM2\n",
    "\n",
    "This notebook demonstrates how to use chat templates with the `SmolLM2` model. Chat templates help structure interactions between users and AI models, ensuring consistent and contextually appropriate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "e13a409cc9ae44b6ac95813e2acdb5a6",
      "071d3ada801e4785aa240c5d3ce772af",
      "2a4f4c2740a0437298e3869fcbd85f27",
      "ce747c18824a4eb186c69698e22dd7dc",
      "518abba501424fe785517868e4772b5a",
      "03e1688e488848099abe3afdd8f64463",
      "69264cf3ef144952b2217058333b8f30",
      "b9eca879237d48bebecd7b9c0caf3a86",
      "3f32d1c6c4eb4ba9b64f61f6705d7b17",
      "ff95208ad2ee4587bda6115d931f8d9e",
      "087f380b1a6a4b5d81164901f8fd0265",
      "ec463c15cef0497895dbfbdf50e59e65",
      "5367de8e7e2e49ccb9afb3b3438f6119",
      "0eb619db4d7645239b6d131397db234e",
      "f6d06a1c941a4028ada60022b8b2b550",
      "d6ebf08bafa04a8e8bf79c7044f5a68d",
      "43a1da14044947d299ad78f8b4ec1967",
      "b98cab4fa567436c8534d4d1306507fd",
      "dd2a3f4b2e6a47628e4b629c9eec6720",
      "86718a2580c04b8787de05b24086f12d"
     ]
    },
    "id": "K-lZu8JvtwUN",
    "outputId": "d7e8bb86-f899-4cf7-be22-994eb283e4f2"
   },
   "outputs": [],
   "source": [
    "# Authenticate to Hugging Face\n",
    "from huggingface_hub import login\n",
    "\n",
    "login()\n",
    "\n",
    "# for convenience you can create an environment variable containing your hub token as HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tnHzBR7vtFlr"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from trl import setup_chat_format\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTVOqbuetFlr"
   },
   "source": [
    "## SmolLM2 Chat Template\n",
    "\n",
    "Let's explore how to use a chat template with the `SmolLM2` model. We'll define a simple conversation and apply the chat template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273,
     "referenced_widgets": [
      "650c95ddf2244111b1b616f09c8f1847",
      "83949466610548d6a9f485f9e2817484",
      "0972a03cbd5749dfa49c69043be6fd6e",
      "77082a2ea31945c2bce164f76c0ba33e",
      "3a7d5fb5efca4af5bfb54049e56f1700",
      "06b8c236e08c4dbfaa7fdba2e4203e83",
      "59fe653d77a9462f9745775c79ae0be3",
      "8f6cd0bb92a2471ea3298f32d9197b7d",
      "15a119525fd548839962783a0fd5d49c",
      "d610ce6e0a5d4c24a1800ebc8e041e96",
      "a8b23ea78a56477fb93074acd847cc88",
      "296efc47cb874d01a4acb9d3736309e2",
      "91988887a8b44546b11c275e24424ec9",
      "27d8287db27f424aac98a8f77e0e7c17",
      "8cde61fd2e364fa69e1dc179138586f1",
      "02ef1dad4f77429bb87839968cfee757",
      "ad2f39ace53a4ace82a4671c857503ff",
      "485d53f4cdb2464cbc9ebf8bd6e2c97a",
      "b7515c6f04d1463cbf5c27a279c5239a",
      "414b2e601b8f4ae7926a69396b01c74d",
      "193f62245bdc405d88a5411f1683ce25",
      "f49b7444963543898d144570397e43a7",
      "b3142de500dc43e1a0a564012a8a40ed",
      "9506cf81ad5743f78152a66a2500bb1c",
      "3e7ecd4846d6435986aeb3cac6f1efd4",
      "a574a379b3064290a0323df66be1f3c8",
      "7aac8f5ca48448999110322618ec52ea",
      "d1555f26741944608fe5210c785a004b",
      "f27fe01833e04753897f4b420a177852",
      "a14d5d4accdb4bb3a87e82f4c4d86273",
      "bab812aa4f5a4d83a6cb2674952cdf18",
      "121372c5acb34cefa0bfa1f78da230e2",
      "c6b38ff449f74135a893a21ee9fb4c45",
      "54792f796e66444aa75fbaf8893e9b90",
      "9368dc6234974a2085b27253e9bcfa4d",
      "83ac78313d59435ba0424bec58c8bbfe",
      "b0375d297b4b4d9b88f0f7ad31dceb90",
      "9f641e7e039541ec83a26589c60f6119",
      "63c6cc53287d429e83ad7a3625434a24",
      "5868186abbeb442f8ba0e9057edf9fdc",
      "625d577b3e324e8193a08140aac57195",
      "1ae2a588644b452d9cb345b5cb83f57f",
      "5c88554cdc5a4e94a93169bb2053e3f5",
      "777da9e047d74415aafb434d7a521941",
      "1f10757711f0461ab3c0ade1a70f66df",
      "29486b27062247cf9175d59e4cf9ef23",
      "a533e337cd5d477a8022871f9bcbfe0b",
      "325993aac6724ddda022c0a7df05b410",
      "01f0be5272474d6db3c1cfcde0bd1742",
      "637daea659ba48f497c5f4b7f6c1fef1",
      "869fff716b8343db9d2fecd12cf7f343",
      "b2f5a09c25a543f2af606bf44636829d",
      "c16260ec318b42f6ad920c3f88680d5e",
      "36869a831eb34479af7e923c2ba5ad8c",
      "d22543d1522044c9b582369e3cbbc38a",
      "d3a37535af3d4eb3aad02201aea75a8e",
      "14159a38f91a48e585cb568d44ef16d4",
      "d5227a37434b4360a53a7e61d90c32ad",
      "609b20049d124f1eb91bc2185d2b8cf6",
      "da554098a8c34d5d8e08295704ce300d",
      "aef0029110614fbbab9d2ef501efbb43",
      "9cdbc12039b74c5ea3a44d1256f1105b",
      "27b5818f1d1b4dc2a605706db9b85164",
      "bad7861e5a354a8b89a8a47ec0ea02ab",
      "7df1185479d44e4895500d6e3479c2b8",
      "47d87cc01f1749fc9c22b6a3f75a0e80",
      "35a840c3efd4454d80adc74fb7f2d283",
      "91f082a95fab496e8a6b8a2e687aa3d4",
      "a7b6adba666e4f11a3e6f3ec6caef777",
      "4f7542f80455414286694119cb6b222f",
      "d079abe1e7bf4094a3fbaf6820e217ea",
      "9de79b58c6aa4b92841890c1326b1c2e",
      "2e28cbe719164666bb32f0c9a61f5fa9",
      "e15892eb4dc34e3f96bf7007dca9360b",
      "f4331d30457344bb9b68087af98153d8",
      "51abf1890f0d4c789ace1d57d49db7de",
      "404d39528e6b40599df5ea773d4d0b7a",
      "e639da4831f6431dbcf6e5a9465513ab",
      "6a18ec7c6ae14ab98becb87a4073d68b",
      "b43a74bdb0f3435d92b3c8cefc30db2e",
      "507a08af481c4e0fbb83e730da3a0f03",
      "ddece435eaff4b3a96fbb04cb91ecbf6",
      "045785cf303b484eb38099706604568e",
      "fb17e798743648f2bd991b7df0013637",
      "76794c8982334d5fbeb29119e63c02d0",
      "5501283e7dfa4eae948f58cadc1be78a",
      "051dc75679dd4a0abd122b4a8b4a14cf",
      "be3b619e7ffa4e2da1cb196dc1790d51"
     ]
    },
    "id": "Nrxh0oX6tFls",
    "outputId": "5205c787-f679-4cbe-f313-e70c57911a0d"
   },
   "outputs": [],
   "source": [
    "# Dynamically set the device\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name\n",
    ").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkJwILrbtFls"
   },
   "outputs": [],
   "source": [
    "# Define messages for SmolLM2\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"I'm doing well, thank you! How can I assist you today?\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ve4dgtjstFls"
   },
   "source": [
    "# Apply chat template without tokenization\n",
    "\n",
    "The tokenizer represents the conversation as a string with special tokens to describe the role of the user and the assistant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pbAg-5x-tFls",
    "outputId": "d8f9bff7-7dcb-44b5-ab4d-58160ded5599"
   },
   "outputs": [],
   "source": [
    "input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "print(\"Conversation with template:\", input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfvdglOqtFls"
   },
   "source": [
    "# Decode the conversation\n",
    "\n",
    "Note that the conversation is represented as above but with a further assistant message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mXUVdPeytFls",
    "outputId": "f396c707-4592-4717-f3d5-d1f75e3e7e23"
   },
   "outputs": [],
   "source": [
    "input_text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=True, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "print(\"Conversation decoded:\", tokenizer.decode(token_ids=input_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcZQpspEtFlt"
   },
   "source": [
    "# Tokenize the conversation\n",
    "\n",
    "Of course, the tokenizer also tokenizes the conversation and special token as ids that relate to the model's vocabulary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jc2PLxAMtFlt",
    "outputId": "01a09b91-2d1a-4427-ed2c-2482f34f31aa"
   },
   "outputs": [],
   "source": [
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "print(\"Conversation tokenized:\", input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3eNp9a0tFlt"
   },
   "source": [
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>Exercise: Process a dataset for SFT</h2>\n",
    "    <p>Take a dataset from the Hugging Face hub and process it for SFT. </p>\n",
    "    <p><b>Difficulty Levels</b></p>\n",
    "    <p>🐢 Convert the `HuggingFaceTB/smoltalk` dataset into chatml format.</p>\n",
    "    <p>🐕 Convert the `openai/gsm8k` dataset into chatml format.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "qbkXV2_ItFlt",
    "outputId": "a9363c45-dc94-4185-9741-89f41cbfc0c1"
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        \"\"\"<iframe\n",
    "  src=\"https://huggingface.co/datasets/HuggingFaceTB/smoltalk/embed/viewer/all/train?row=0\"\n",
    "  frameborder=\"0\"\n",
    "  width=\"100%\"\n",
    "  height=\"360px\"\n",
    "></iframe>\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "d1439cd006574149bfa4161afe72a589",
      "3033b6a4495948ccb647d960654c14ff",
      "631ed59e31e449a9ac3981525f5e9d78",
      "8e63ed1ae75d4bfd84e077e5facf7a93",
      "137ec148afc049eebadf3dd5723e19e1",
      "d3a1a275936f4c2ea7a236be655dde89",
      "ec2400e96b644f18a5b9b788ed5c5f8a",
      "715b6d3c1bc3471b8813bfec1b46d64b",
      "98ec6b5597e34d1bb4a6527d08e3f232",
      "747600742f154e16b988df20e6a925af",
      "565b69e01a23452688b7a6b9f350eeaf",
      "24a9af4d55ee498d971badfbadc5a033",
      "ff5568a48b234f96895d3373d95c126f",
      "3adb52836c4f44928e0d1aab42fc9a13",
      "ef191fdc0b8345229b54e836b0ce2009",
      "2b1bb9e844fd4e8284fff749a4fbd74b",
      "a59073566ea347bd8d47a54e229e6d83",
      "aa1a63cdae7246459c36b9875417544a",
      "4b9b4f6c43314d61b7d04991386ce17a",
      "a5449e9729044551b578053765870759",
      "9da73dd4f2fa4d7690234489d4477fdc",
      "1bf8001b5811470ba557afe865bc6354"
     ]
    },
    "id": "4p3atw4_tFlu",
    "outputId": "276e7f32-df9b-465b-e3d2-1ca636e85a46"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"HuggingFaceTB/smoltalk\", \"everyday-conversations\")\n",
    "\n",
    "\n",
    "def process_dataset(sample):\n",
    "    # TODO: 🐢 Convert the sample into a chat format\n",
    "    # use the tokenizer's method to apply the chat template\n",
    "    messages = sample[\"messages\"]\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    sample[\"prompt\"] = prompt  # Store formatted prompt in a new field\n",
    "    return sample\n",
    "\n",
    "\n",
    "ds = ds.map(process_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1tHPh9YWPwc",
    "outputId": "e7b54a41-c2cf-4333-87fc-73a1ac4c9609"
   },
   "outputs": [],
   "source": [
    "print(ds[\"train\"][0][\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5C7gZIaUStF",
    "outputId": "b50e1f83-166b-46d3-d4a9-43d14ebd8689"
   },
   "outputs": [],
   "source": [
    "print(ds[\"train\"][0][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "81fQeazltFlu",
    "outputId": "d59904eb-4c3d-40d7-a9df-c3a23c1fc7eb"
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    HTML(\n",
    "        \"\"\"<iframe\n",
    "  src=\"https://huggingface.co/datasets/openai/gsm8k/embed/viewer/main/train\"\n",
    "  frameborder=\"0\"\n",
    "  width=\"100%\"\n",
    "  height=\"360px\"\n",
    "></iframe>\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "27360f72733e4d25a706b41a4fc583b9",
      "d8ff90fe277d4573a2b790e6126d36d8",
      "5a710cb0e74747cb90800d9046fb98d4",
      "739af31f0d794fbe8b7125dbbc2b5d5a",
      "cf20fe5d6435469ca11d25ea7387b179",
      "6267794b074342e89cbf47abe147ee40",
      "1b707ed13e1243c58477c06a8f5d92e7",
      "89597c008bb24bce99ec12387c45d73d",
      "4ffe411162594909a011c66d7a713516",
      "4c509a706b1f4e4790f067149837c37a",
      "5cdb1497a2b645809b8944fe0ff47ad3",
      "1503d145fb85421bb27922f95f88608b",
      "1ab1f78f275d49139daacdc893d3bfa8",
      "dafb415cb94f4f228b1e97f494cc3932",
      "5aa3ea3b23b14f22ae8a4aaa08f89bd7",
      "d1a73820599d431bbd79a5709c140ea8",
      "90ba34c204314708a5f16e0b19f61699",
      "12715fd70e0a48208a547efee665b943",
      "03101acebdcb4e7fb79dfedb908fba2e",
      "17e85a7b3be64e75811a5557d13bc74b",
      "5a9d3adb3b7d476fb08e64e11400a753",
      "0730e84266f04e16b159f27f25435ac0",
      "67848d94a13f451ebbe5e209f44e566b",
      "7266903c0c924ce98e1fa67f12ecaef8",
      "3633489f42ce4923b03267deb8fa06fc",
      "3319a1a05be342e9af285e3c118272ce",
      "7ea61bf4ef8241a287e4b03452b6babc",
      "256b9b4aa89a4b62ab9c0e3469155b41",
      "195b083ad6b1419db56c55c6b71f5f4e",
      "88d09d0edb1a4f32a36a2069f6167af1",
      "630f6a7a9bfd45cf966a269fdfb840b6",
      "6087bbe86c4142cdb5685fc42163a86e",
      "a673e11923984f7ba0c56280a4469559",
      "d38cbc5cb7d34db1a13fdf602379a4d9",
      "e3fedf7ca44246c79b59baefc3b0d1a4",
      "67612a98bc384df09a7cda8d56f22c1c",
      "28d4e87a2ccd42b2a9798dee3a15c70c",
      "dc4a71be7aaa4324a9f3942af873bd7d",
      "a89ae254d7aa4c909a8d2a56c9c7c5e7",
      "ed6eb883b17b4d748f583020726f9bd1",
      "3124cba36313496ba9f84eb49c6db041",
      "d41b1b4e69434d68855620d1ec94ce4a",
      "647c05d1ca5b4837b4375575b1bf053a",
      "c725bb76d9904875b5f49da631a06441",
      "dd80583e06e544cd9dff372b92e9bb83",
      "f0f0da427d2b4728a4e99cdf57508021",
      "d737d4ac19c54c29a083a8413a76deaf",
      "7f7d038cea6545f18c66e373c2750ad1",
      "8b082a9738494c8683111fdccf94aefe",
      "e8c744f65ab741058960e310ba6fadc6",
      "f1dda9de52dd461aa3e0a73adf744143",
      "e8e57b6002b842148374b05b905b8503",
      "2f52b2198a5f4b15ac7762acae88a187",
      "674c825cd75846b98f050bfe962afbd0",
      "630df9c8f33f4300b4afd1ec19c858dc",
      "dd015d8e837041ba9a94e928efd82313",
      "057c2beabd224819b6e6bdf5f6eb29d7",
      "f50a1ff197de43a9b612da6076d20b3c",
      "4732af51f4b9437c8f1bf223c6a76060",
      "a89d3e8dded044eb97007b51dfcce998",
      "b6fa5c11638f469196f06a126a500c99",
      "46b025d5c5bf47ddaf4b687e98a7e6f9",
      "6c809184ce7a4b79b8aafb670a738c84",
      "f0557e3bce9141208f31478f2b998618",
      "5539b4ccd39f488c9a3bed679b0f0eb6",
      "308ec84202f441ab8c5fc12c558f6b9d",
      "50f7bbe7585c42059dfab8880627cfce",
      "e9be8cdf0b4a46c1a6b651c35d3c7465",
      "5eae3ce0d4c84b2697f17b58367ac07b",
      "67946d0c77534d7a86f145a72c95c773",
      "240c1d658cc74220a82d759ef42f428f",
      "cb53c50777ae46e3a08b13f5255fd364",
      "f983172b72974d61854de6c9ea917e67",
      "9b696f3c356640a5a15af04702e57e81",
      "1a8421ba8147469cab020161c1d85469",
      "de67f7112dd548af99bf9e97f4f4165c",
      "98caf0e84a394c51acb441652ed97533"
     ]
    },
    "id": "bWUSv7NMtFlu",
    "outputId": "a6be2b7c-cdca-4391-a012-4307473ef6a2"
   },
   "outputs": [],
   "source": [
    "ds = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "\n",
    "\n",
    "def process_dataset(sample):\n",
    "    # TODO: 🐕 Convert the sample into a chat format\n",
    "\n",
    "    # 1. create a message format with the role and content\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": sample[\"question\"]},\n",
    "        {\"role\": \"assistant\", \"content\": sample[\"answer\"]},\n",
    "    ]\n",
    "    # 2. apply the chat template to the samples using the tokenizer's method\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    sample[\"prompt\"] = prompt  # Store formatted prompt in a new field\n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "ds = ds.map(process_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQRkHIKAVgWV",
    "outputId": "30dcd9cc-fe32-4cf8-be39-55ba29fa4c38"
   },
   "outputs": [],
   "source": [
    "print(ds[\"train\"][0][\"prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlXCuRKotFlu"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to apply chat templates to different models, `SmolLM2`. By structuring interactions with chat templates, we can ensure that AI models provide consistent and contextually relevant responses.\n",
    "\n",
    "In the exercise you tried out converting a dataset into chatml format. Luckily, TRL will do this for you, but it's useful to understand what's going on under the hood."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
